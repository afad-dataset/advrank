Adversarial Ranking Attack and Defense (ECCV2020)
===

Additional Materials for ECCV-2020 #2274 "Adversarial Ranking Attack and Defense".

Authors: Mo Zhou, Zhenxing Niu, Le Wang, Qilin Zhang, Gang Hua.

1. Preprint: https://arxiv.org/abs/2002.11293
2. The full preprint version (including more graphics than the arxiv version) can be found in this repo.
2. Code is coming soon.

## Abstract

![advranking](assets/advranking.png)

Deep Neural Network (DNN) classifiers are vulnerable to adversarial attack,
where an imperceptible perturbation could result in misclassification. However,
the vulnerability of DNN-based image ranking systems remains under-explored. In
this paper, we propose two attacks against deep ranking systems, i.e.,
Candidate Attack and Query Attack, that can raise or lower the rank of chosen
candidates by adversarial perturbations. Specifically, the expected ranking
order is first represented as a set of inequalities, and then a triplet-like
objective function is designed to obtain the optimal perturbation. Conversely,
a defense method is also proposed to improve the ranking system robustness,
which can mitigate all the proposed attacks simultaneously. Our adversarial
ranking attacks and defense are evaluated on datasets including MNIST,
Fashion-MNIST, and Stanford-Online-Products. Experimental results demonstrate
that a typical deep ranking system can be effectively compromised by our
attacks. Meanwhile, the system robustness can be moderately improved with our
defense. Furthermore, the transferable and universal properties of our
adversary illustrate the possibility of realistic black-box attack. 

## Visualization Examples

Under preparation.
